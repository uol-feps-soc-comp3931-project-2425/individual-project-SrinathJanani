Progress Notes :
================


29/1/2025 Notes

Code finally works using Ohollo's Chord Detection
• python versions 2.7, 3.6, 3.9 and 3.10 did not work
-> python version 3.8 finally worked
• vamp continuously threw errors during installment
-> vamp had to be manually downloaded and configured to path
• the library threw errors when pip installing
-> the library had to be installed using the GitHub url
• there were multiple complications with other required libraries and library versions (example, numpy)
-> these issues somehow resolved automatically after completing the above fixes
• other chord detection libraries offered similar issues and bugs
• often libraries or required components didn't have helpful enough documentation

After much deliberation and testing, the chord detection library has successfully been installed for python3.8

Implemented Features :
• defining the extractor object (courtesy of Chordino)
• extracting chords and their respective timestamps from locally stored songs (one at a time)
• storing the above features from a 'ChordChange' object instead into arrays
• splicing the storage location to obtain the song name and artist

Upcoming Features :
• designing an object to store
  - song name
  - music artist
  - key signature
  - chord progression (universal notation) with timestamps (dictionary/array)
  - (optional - release date)
• creating a naming convention for song files, which must include
  - song name
  - music artist
  - key signature (to make universal chord progression notation)
• looping over extracting from multiple songs (say, in a folder)
• verifying detection accuracy (currently speculated at roughly 80%)

Future Implementations :
• compiling database of songs (possible to use top X number of songs on spotify for each year over a duration of time)
• researching on machine learning technique to classify and regress data
• installing and importing machine learning models
• training the model against the data, and subsequently testing for similarities with new songs

Additional Possibilities :
• designing an app to interact with data and display outputs
• designing a method to record audio, from which chords can be extracted

__________

30/1/2025

Note : other potential chord extraction softwares that were considered
https://github.com/orchidas/Chord-Recognition
https://github.com/belovm96/chord-detection/tree/master?tab=readme-ov-file#Usage
https://pypi.org/project/chorder/
https://pypi.org/project/autochord/#description

An issue with depending on externally provided key signature is that this will also need to be provided when testing with audio, and this results in excess effort when making a custom recording or if the song's scale is unknown to the user.
Hence it is more optimal to have a key signature identification algorithm to detect the scale.

__________

31/1/2025

The following method aims to calculate the key signature of a song, given the chord extraction output.
This method is inspired from "https://www.oajaiml.com/uploads/archivepdf/74301105.pdf" (Section 3.2, page 77)

The key signature can be estimated by taking all extracted notes and comparing them to all possible scales, and select the scale with the most number of chords detected part of that scale.
Due to the rarity of chords appearing outside of the scale especially in pop songs, this method should hypothetically have high accuracy.

Simplifying the algorithm :

• A problem arises with variations of a chord from the same starting note (example,  "F" "F#" "F#5" "F#7" "F#m" "F#m7" "F#sus4" "F2" "F5" "F6" "F7" "F7sus4" "Fm" "Fm13" "Fm7" "Fmaj" "Fmaj7")
-> These can be stripped down to just the essential chords, i.e F and Fm (starting from F), and F# and F#m (starting from F#). This castly reduces the number of computations required.

• Of all the scales available, the main 2 "major" and "minor" scales will be considered. This means for 12 notes and 2 variations of each note, there are 24 total possible key signatures.
-> In music theory, there is a relation between minor and major scales where the third note of a minor scale forms a major scale using the exact same chords. This reduces the number of scales to just 12. 

• Each note will have to be verified among every scale. But a convenient trick to use would be to represent all possible scales by their note as a binary sequence. In the sequence, each digit corresponds to whether the chord is present in that scale.
-> Hence [ A, A#/Bb, B, C, ... , G, G# ] will be converted to a 12 digit binary sequence.

• Instead of checking every single scale, it is notable that the 1st 4th and 5th chords are major, the 2nd 3rd and 6th chords are minor, and the 7th chord can either be considered both major or minor.
i.e given a major chord for example, we would only need to find the scales where that chord is the 1st chord (C major scale), the 4th chord (G major scale), the 5th chord (F major scale), or possibly the 7th chord (C# major scale).
-> Hence any chord will only appear in 1 of 4 scales. The above example of C major chord would result in binary output 000110001010

• Moving a scale by i notes, each note in the scale also moves by i positions.
-> this means that a chord 'i' notes ahead will (cyclic) shift right by i positions
for example, the d major chord, which is 2 positions ahead of c major, will be represented by 100001100010 i.e A major (4th chord), D major (1st chord), D# major (plausible 7th chord) and G major (5th chord)
-> this additionally implies that only 2 binary sequences are required to be stored (1 for major, 1 for minor), and cyclic shift operations can be performed on it to indicate which scales it is part of.
-> this technique also accounts for both major and minor chords of a given note, readily being able to use either sequence depending on whether it is a major or minor chord.

->> Hence given an extracted chord, the first letter is selected. If the second position is "#" or "m", it is also extracted. If the second position was "#", if the third position is "m" then it is also selected. 
Then based on the distance from A, the respective binary sequence is selected and cyclic shift can be performed on it.
These binary vectors will be added together for each extracted chord, and the position with the highest count is highly probable to be the key signature of the song.

Pseudo-code
>>> key_signature_array = [0,0,0,0,0,0,0,0,0,0,0,0]
>>> for chord in extraction_array:
>>> position_diff = ['A', 'A#', 'B', 'C', ... , 'G', 'G#'].index(chord)
>>> sequence = [ [1,1,0,0,0,1,0,1,0,0,0,0] , [0,1,0,1,0,0,0,0,1,0,1,0] ].index(any(x=="m" for x in chord))
>>> scale_array = cylic_shift(sequence, position_diff)
>>> key_signature_array += scale_array
>>> key_signature = max(key_signature_array)

__________


3/2/25

Note :
Detailed explanation of roman numerical chord (triad) representation is given in
https://www.musictheory.net/lessons/44
https://www.musictheory.net/lessons

The current prototype of the pre-solution obtains a good estimate for the key signature when the extracted chords have good accuracy.
Given extracted chords and a key signature, the machine learning model will need to access chord progressions not as the actual notes being, but as the relative distance from the starting note.
This is notationally represented as I (root note), II, III, IV, V, VI, and VII

Since different songs use different scales, the universal way to compare different chord progressions is to use the roman numerals system.
Hence an algorithm is required which converts notes to their respective roman numeral representation, depending on the key signature of the song.

This can be achieved by cyclicly shifting the previously used array for storing the scale notes i.e ['A', 'A#', ... , 'G#'] to start with the root note of the scale, and comparing the notes to the index of this array, they can be converted via the same position of an array ['I', 'bII', 'II', 'bIII', ... , 'bVII', 'VII']
This conversion can hence be stored in a seperate array, which will be used for the training data.

Note: The useful music theory required for this section is
• Each chord is a "triad", a set of 3 notes seperated by a note each
• The chord is labelled with a roman numeral by the numerical position of the first note of that chord
-> i.e the chord from the first note is labelled as I, the chord from the second note is labelled as II, etc
• Major chords are represented in capital (i.e II, VI) and minor chords are represented in lower case (i.e ii, vi)
• A 'Flat' (b) represents that the note is played exactly one position below the written note next to it (i.e Ab is played as the note to the left of A)
• A 'Sharp' (#) represents that the note is played exactly one position above the written note next to it (i.e A# is played as the note to the right of A)
• In case a chord is not part of the scale (since the scale only uses 7 of the total 12 notes), then it is written with a sharp or flat to the left of the chord (i.e bIII, #iv)
• Though there is much more musical notation, this study shall limit the notational use to this amount (to make it easier for classication)

__________

